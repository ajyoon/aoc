{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Anxiety of Conception Algorithm\n",
    "\n",
    "This notebook contains the code and explanation for how the poems of my book, \"The Anxiety of Conception,\" are ordered. \n",
    "\n",
    "I wrote one hundred prose poems (single paragraphs) in the year prior to J's birth, and one hundred in the year after. Let's call these two sets of poems **poems a** (pre-birth poems) and **poems b** (post-birth poems). The book also has two parts: *PART 1* and *PART 2*. In the first printings, most poems from **poems a** are in *PART 1*, but over time the poems begin to swap and get muddled, such that by the 200th book the poems are mostly shuffled.\n",
    "\n",
    "How are the poems shuffled? There is an algorithm which calculates a score for how \"well\" a poem would go after another one. Some poems go well together---these get a low score (or `small distance`; this terminology will be explained later)---others don't match very well and get a high score (or `large distance`). As books are printed, poems are rearranged according to this score, such that poems that go \"well\" together according to their score are adjacent, even if very far apart in the original ordering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Step 1: Import the poems\n",
    "\n",
    "### Text import\n",
    "\n",
    "Import poems from **poems a** and **poems b**. Subset each set to just 100 poems each. (Eventually there should just be exactly 100 poems in each part.) Then put them together into one large list which is referenced for the rest of the code, and just know that the first 100 are from **poems a** and the second 100 from **poems b**.\n",
    "\n",
    "The output of the algorithm which creates books will be an ordering: this will be a list of indices of this original list of poems. i.e. There are poems 0, 1, 2, 3, 4, ... 199. The output will be a list something like 5, 90, 23, 1, ... 182, representing the order in which the poems should be printed in the book.\n",
    "\n",
    "Note that the imported text looks something like:\n",
    "\n",
    "```\n",
    "[1] Poem text here.\n",
    "\n",
    "[2] Another poem text here.\n",
    "```\n",
    "\n",
    "Right now I'm removing the numbers in brackets, but I may consider putting them back later.\n",
    "\n",
    "### Words and stems\n",
    "\n",
    "In addition to tracking the raw text of each poem, I also split each poem into a list of lowercase words with punctuation removed, and a list of word stems (e.g. instead of \"computer\" the word becomes the stem \"comput\"). This is then used when calculating the score (or distance) between poems, as described later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def simple_tokenize(s):\n",
    "    \"\"\"where s is a string of text, raw poem\"\"\"\n",
    "    s = s.lower()\n",
    "    s = s.translate(str.maketrans('', '', string.punctuation))\n",
    "    return s.split(\" \")\n",
    "\n",
    "def get_stems(s):\n",
    "    \"\"\"where s is a list of lowercase words\"\"\"\n",
    "    return [stemmer.stem(w) for w in s]\n",
    "\n",
    "\n",
    "data_raw = []\n",
    "data_tokens = []\n",
    "data_stems = []\n",
    "\n",
    "# first add part a\n",
    "with open(\"part_a.txt\", \"r\") as fle:\n",
    "    for line in fle:\n",
    "        if line[0] == \"[\":\n",
    "            text = line.split(\"]\")[1].strip()\n",
    "            data_raw.append(text)\n",
    "\n",
    "            tokens = simple_tokenize(text)\n",
    "            data_tokens.append(tokens)\n",
    "\n",
    "            stems = get_stems(tokens)\n",
    "            data_stems.append(stems)\n",
    "\n",
    "# cut it to just 100 poems\n",
    "data_raw = data_raw[:100]\n",
    "data_tokens = data_tokens[:100]\n",
    "data_stems = data_stems[:100]\n",
    "\n",
    "poems_a = list(range(len(data_raw)))\n",
    "\n",
    "# then add part b\n",
    "with open(\"part_b.txt\", \"r\") as fle:\n",
    "    for line in fle:\n",
    "        if line[0] == \"[\":\n",
    "            text = line.split(\"]\")[1].strip()\n",
    "            data_raw.append(text)\n",
    "\n",
    "            tokens = simple_tokenize(text)\n",
    "            data_tokens.append(tokens)\n",
    "\n",
    "            stems = get_stems(tokens)\n",
    "            data_stems.append(stems)\n",
    "\n",
    "data_raw = data_raw[:200]\n",
    "data_tokens = data_tokens[:200]\n",
    "data_stems = data_stems[:200]\n",
    "\n",
    "poems_b = list(range(poems_a[-1]+1, len(data_raw)))\n",
    "\n",
    "split_index = poems_a[-1] + 1\n",
    "\n",
    "print(poems_a)\n",
    "print(poems_b)\n",
    "print(split_index)\n",
    "data_raw[0], ' '.join(data_tokens[0]), ' '.join(data_stems[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Step 2: Calculate transition scores\n",
    "\n",
    "i.e. How well one poem flows into another. \n",
    "\n",
    "Look at the 10 words at the end of one poem, the 10 at the start of the next. High score is better, but then we'll invert it so that score is more like distance (where lower is better).\n",
    "\n",
    "Initial score: 0\n",
    "\n",
    "If a word in poem B is in poem A:\n",
    "\n",
    "* If not a stop word:\n",
    "    * +20 if exact word match OR\n",
    "    * +10 if stemmed word match\n",
    "* If narrow stop word:\n",
    "    * +2\n",
    "* If broad stop word\n",
    "    * +4\n",
    "    \n",
    "Not implemented: \n",
    "\n",
    "* Check number of words between them (k) -- could be up to 18\n",
    "    * -k/4\n",
    "\n",
    "I'd like this score to be a bit cleaner, and maybe consider distance between words, but this is working pretty well for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_broad = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "stopwords_narrow = [\"the\", \"a\", \"an\"]\n",
    "\n",
    "def join_score(a, b, n=10):\n",
    "    \"\"\"where a and b are indices for the data, and n is num of words to consider\"\"\"\n",
    "    score = 0\n",
    "    a_tokens = data_tokens[a]\n",
    "    a_stems = data_stems[a]\n",
    "    b_tokens = data_tokens[b]\n",
    "    b_stems = data_stems[b]\n",
    "    for i in range(min(len(a_tokens), n)): # iterate over words in a\n",
    "        a_token = a_tokens[-i]\n",
    "        a_stem = a_stems[-i]\n",
    "        for j in range(min(len(b_tokens), n)): # iterate over words in b\n",
    "            b_token = b_tokens[j]\n",
    "            b_stem = b_stems[j]\n",
    "            if a_token == b_token: # if there's a matching word\n",
    "                if a_token in stopwords_narrow:\n",
    "                    score += 2\n",
    "                    continue\n",
    "                if a_token in stopwords_broad:\n",
    "                    score += 4\n",
    "                    continue\n",
    "                score += 20\n",
    "                continue\n",
    "            if a_stem == b_stem:\n",
    "                score += 10\n",
    "    return 20 - score\n",
    "\n",
    "p = 2\n",
    "q = 3\n",
    "print(data_raw[p], \"\\n\")\n",
    "print(data_raw[q])\n",
    "join_score(p, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Calculate the score for all possible pairs of poems. This results in a square matrix the size of how many poems there are (200)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calc_all_scores(data, join_score_func):\n",
    "    scores = np.empty([len(data), len(data)])\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data)):\n",
    "            if i == j:\n",
    "                s = np.nan\n",
    "            else:\n",
    "                s = join_score_func(i, j)\n",
    "            scores[i][j] = s\n",
    "    return scores\n",
    "\n",
    "scores = calc_all_scores(data_raw, join_score)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Step 2a: See which poems fit together best\n",
    "\n",
    "This is just to check that the join scores are working okay.\n",
    "\n",
    "Remember: lower is better, because the scores are considered as `distances` between the poems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_scores(scores, asc=True, n=5):\n",
    "    flattened = scores.flatten()\n",
    "    if asc:\n",
    "        sorted_indices = np.argsort(flattened)\n",
    "    else:\n",
    "        sorted_indices = np.argsort(-flattened)\n",
    "    indices_2d = np.unravel_index(sorted_indices, scores.shape)\n",
    "    sorted_indices_list = list(zip(indices_2d[0], indices_2d[1]))\n",
    "\n",
    "    for i, val in enumerate(sorted_indices_list[0:n]):\n",
    "        print('indices:', val)\n",
    "        print('score:', scores[val[0],val[1]])\n",
    "        print('>>>', data_raw[val[0]], '\\n>>>>', data_raw[val[1]], '\\n')\n",
    "\n",
    "    return sorted_indices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_top_scores(scores, asc=True, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Step 3: Reorder the poems according to the scores\n",
    "\n",
    "### A single tour (if we don't care about the two parts and mixture levels)\n",
    "\n",
    "This is a traveling salesman problem with assymmetric distances. To keep in line with traveling salesman terminology, each poem is a `city`, and the ordering of the poems is called the `tour`. The scores between poems are `distances`. It's assymmetric because the distance between two poems (cities) depends on their order.\n",
    "\n",
    "The algorithm calculates a `tour` which visits each city once. I'm going to use a Markov Chain Monte Carlo (MCMC) method to stochastically find a good tour. The basic idea is to start with a random tour, and then randomly swap cities (poems) and check if the new tour is better; if it's better then we keep the new tour, if it's not better we discard it and just try another random swap. If we repeat this many, many times the tours will start to get better and better, even though each swap is random. However, to avoid local minimums, we add some wiggle room (in the code this is the `temperature`) for selecting a slightly less optimal tour. We'll add in what's called simulated annealing, which means we'll decrease the wiggle room as we go on, which has been shown to be a good technique.\n",
    "\n",
    "### A double tour (caring about the mixture of the two parts)\n",
    "\n",
    "Actually, I have two tours: the cities (poems) of *PART 1*, and the cities (poems) of *PART 2*. Both should be close-to-optimal, i.e. poems that sit well together should be together. \n",
    "\n",
    "<!-- I'd like to be able to create mixtures of part A and part B. To do this, I set a mixture percentage, and then randomly swap that percentage of cities. So let's say the percentage is 30%. I randomly select 30% of cities from part A and swap it with 30% from part B. Let's imagine cities have colors, and those colors represent which part they originally come from. So originally we have blue cities in part A and red cities in part B. Then we mix 30%. Now part A is mostly blue, but with some red, and part B is mostly red, but with some blue. -->\n",
    "\n",
    "We will do the MCMC on the tour like above, but with a constraint on how cities can be swapped. Normally, with a single tour, you can swap any city with any other. Now, swaps may change the mixture level. If we run the algorithm with no constraint on the mixture, it will very quickly go to about 50%. So instead we'll make the mixture level fixed. At the start, we will swap poems to set the mixture level, and then disallow swaps that would change the mixture level.\n",
    "\n",
    "If you want the mixture level to remain the same, you can constrain which cities can be swapped. To keep the mixture level constaint, a city can be swapped with:\n",
    "\n",
    "* any other city in the same part (e.g. if from *PART 1*, it can be swapped with any other city in *PART 1*)\n",
    "* any other city from the same poem set (e.g. if a poem from **poems a**, it can be swapped with any other poem from **poems a**)\n",
    "\n",
    "A final note: when we decide if we want to keep a swap, we want to calculate the distance of each tour independently (the tour through *PART 1* and the tour through *PART 2*) and then only accept a swap if *both* tours improve.\n",
    "\n",
    "### A note on optimality\n",
    "\n",
    "It is very computationally expensive to find the optimal tour. Instead, MCMC gives us a close-to-optimal tour. What is nice about MCMC is that because it finds a close-to-optimal tour stochastically, you can run the algorithm multiple times and get multiple distinct tours all of which are close-to-optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses the following variables from above:\n",
    "# poems_a, poems_b, split_index\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "def calculate_total_distance(tour, distance_matrix):\n",
    "    return sum(distance_matrix[tour[i]][tour[i+1]] for i in range(len(tour)-1))\n",
    "\n",
    "def swap_cities(tour):\n",
    "\n",
    "    # Step 1: Randomly sample the first city\n",
    "    i = np.random.randint(len(tour))  # Random index\n",
    "    city = tour[i]                    # City identifier at that index\n",
    "\n",
    "    # Step 2: Determine the swaps that don't change the mixture level\n",
    "    current_section = tour[:split_index] if i < split_index else tour[split_index:]\n",
    "    opposite_section = tour[split_index:] if i < split_index else tour[:split_index]\n",
    "\n",
    "    if city in poems_a:\n",
    "        # Include all poems in the current section plus poems_a in the opposite section\n",
    "        acceptable_swaps = np.concatenate((current_section, opposite_section[np.isin(opposite_section, poems_a)]))\n",
    "    else:\n",
    "        # Include all poems in the current section plus poems_b in the opposite section\n",
    "        acceptable_swaps = np.concatenate((current_section, opposite_section[np.isin(opposite_section, poems_b)]))\n",
    "\n",
    "    # Step 3: Sample from acceptable_swaps, then find index of that sample in current tour\n",
    "    sample_city = np.random.choice(acceptable_swaps, 1)[0]\n",
    "    j = np.where(tour==sample_city)[0][0]\n",
    "\n",
    "    # Step 4: Swap the cities in the tour\n",
    "    new_tour = tour.copy()\n",
    "    new_tour[i], new_tour[j] = new_tour[j], new_tour[i]\n",
    "\n",
    "    return new_tour\n",
    "\n",
    "def solver(distance_matrix, iterations, initial_temperature, mixture, down_sample=100, seed=None):\n",
    "\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # mixture should be an int between 0 and 100\n",
    "    # here we're just assuming that there are 100 poems in each part\n",
    "    # just makes the mixing easier to implement in code\n",
    "    # since it doesn't really matter which poems get swapped, we just swap from the start\n",
    "    tour_a = np.array(poems_b[:mixture] + poems_a[mixture:])\n",
    "    tour_b = np.array(poems_a[:mixture] + poems_b[mixture:])\n",
    "\n",
    "    current_tour = np.concatenate((tour_a, tour_b))\n",
    "\n",
    "    current_distance_a = calculate_total_distance(tour_a, distance_matrix)\n",
    "    current_distance_b = calculate_total_distance(tour_b, distance_matrix)\n",
    "\n",
    "    best_tour = current_tour\n",
    "    best_distance_a = current_distance_a\n",
    "    best_distance_b = current_distance_b\n",
    "\n",
    "    temperature = initial_temperature\n",
    "\n",
    "    # these lines are for recording details as iterations progress\n",
    "    down_sample = 100\n",
    "    distance_array_a = np.empty(int(iterations/down_sample))\n",
    "    distance_array_b = np.empty(int(iterations/down_sample))\n",
    "    temperature_array = np.empty(int(iterations/down_sample))\n",
    "    array_index = 0\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "\n",
    "        new_tour = swap_cities(current_tour)\n",
    "\n",
    "        new_distance_a = calculate_total_distance(new_tour[:split_index], distance_matrix)\n",
    "        new_distance_b = calculate_total_distance(new_tour[split_index:], distance_matrix)\n",
    "\n",
    "        delta_distance_a = new_distance_a - current_distance_a\n",
    "        delta_distance_b = new_distance_b - current_distance_b\n",
    "\n",
    "        if iteration % down_sample == 0:\n",
    "            distance_array_a[array_index] = current_distance_a\n",
    "            distance_array_b[array_index] = current_distance_b\n",
    "            temperature_array[array_index] = temperature\n",
    "            array_index += 1\n",
    "\n",
    "        if delta_distance_a < 0 or np.random.random() < math.exp(-delta_distance_a / temperature):\n",
    "            if delta_distance_b < 0 or np.random.random() < math.exp(-delta_distance_b / temperature):\n",
    "\n",
    "                current_tour = new_tour\n",
    "                current_distance_a = new_distance_a\n",
    "                current_distance_b = new_distance_b\n",
    "\n",
    "                if new_distance_a < best_distance_a and new_distance_b < best_distance_b:\n",
    "                    best_tour = new_tour\n",
    "                    best_distance_a = new_distance_a\n",
    "                    best_distance_b = new_distance_b\n",
    "\n",
    "        temperature *= 0.999  # Cooling schedule\n",
    "\n",
    "\n",
    "    tracking_data = {\n",
    "        'dist_arr_a': distance_array_a,\n",
    "        'dist_arr_b': distance_array_b,\n",
    "        'temp_arr': temperature_array,\n",
    "    }\n",
    "    return best_tour, tracking_data\n",
    "\n",
    "\n",
    "dist_matrix = scores  # the asymmetric distance matrix\n",
    "iters = 10000 # seems like it takes at least 10,000 iterations to stabilitize\n",
    "temp = 100\n",
    "mixture = 5\n",
    "\n",
    "now = time.time()\n",
    "best_tour, tracking_data = solver(dist_matrix, iters, temp, mixture, seed=30324)\n",
    "print(\"Time to run:\", time.time() - now)\n",
    "print(\"Best Tour:\", best_tour)\n",
    "print(\"Best Distance:\", tracking_data['dist_arr_a'][-1], tracking_data['dist_arr_b'][-1])\n",
    "print(\"Final temperature:\", tracking_data['temp_arr'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Step 4: See how well the solver is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ms = 1 # marker size\n",
    "\n",
    "# Generate x-axis values (indices of the array)\n",
    "indices = np.arange(len(tracking_data['dist_arr_a']))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, sharex=True, figsize=(8, 6))\n",
    "fig.suptitle('MCMC to solve TSP (x axis is iterations)')\n",
    "\n",
    "# Create a line plot\n",
    "ax1.scatter(indices, tracking_data['dist_arr_a'], c='b', marker='o', s=ms)\n",
    "ax1.scatter(indices, tracking_data['dist_arr_b'], c='c', marker='o', s=ms)\n",
    "ax1.legend([\"A tour\", \"B tour\"])\n",
    "ax1.set_ylabel('Tour Distance')\n",
    "\n",
    "ax2.scatter(indices, tracking_data['temp_arr'], marker='o', s=ms)\n",
    "ax2.set_ylabel('Temperature')\n",
    "ax2.set_xlabel('Iteration/100')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tour_scores(tour):\n",
    "    score_list = []\n",
    "    for i in range(len(tour)-1):\n",
    "        score_list.append(scores[tour[i], tour[i+1]])\n",
    "    return score_list\n",
    "\n",
    "random_tour = np.random.permutation(len(data_raw))\n",
    "\n",
    "best_score_list = get_tour_scores(best_tour)\n",
    "rand_score_list = get_tour_scores(random_tour)\n",
    "\n",
    "indices = np.arange(len(best_score_list))\n",
    "\n",
    "# Create a line plot\n",
    "plt.plot(indices, best_score_list, c='b', marker='.')\n",
    "plt.plot(indices, rand_score_list, c='r', marker='.')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('red is random tour, blue is best tour')\n",
    "plt.xlabel('point along tour')\n",
    "plt.ylabel('distance between points')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, index in enumerate(best_tour[:10]):\n",
    "    poem = data_raw[index]\n",
    "    score = scores[best_tour[k], best_tour[k+1]]\n",
    "    print(poem)\n",
    "    print(\"\\n\", score, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Step 5: Calculate breathing / break points\n",
    "\n",
    "To let the poems breath a little bit, find the poems with the most distance between them to create more vertical space between some of the poems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_break_points(tour, percent=20):\n",
    "    \"\"\"score_list returns the score of poem i to poem i+1,\n",
    "    so if a breakpoint has index i, the break should come\n",
    "    after poem i.\"\"\"\n",
    "    score_list = get_tour_scores(tour)\n",
    "    ordered = np.argsort(score_list)[::-1]\n",
    "    return ordered[:percent]\n",
    "\n",
    "get_break_points(best_tour)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Step 6: Calculate mixture levels\n",
    "\n",
    "As book printing progresses, the mixture level should increase and then oscillate. Below is a simple function that lets the mixture level oscillate with some randomness while still increasing over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30324)\n",
    "\n",
    "num_books = 2000\n",
    "\n",
    "level = 0 # this is the mixture level\n",
    "level_arr = np.empty(num_books)\n",
    "for i in range(num_books):\n",
    "#     change = random.choices([-1,0,+1], weights=[level+20,50,120-level])[0]\n",
    "    weights = np.array([level + 20, 50, 120 - level])\n",
    "    probabilities = weights / weights.sum()\n",
    "    change = np.random.choice([-1, 0, 1], p=probabilities)\n",
    "    level = level + change\n",
    "    level = min(max(0, level), 100)\n",
    "    level_arr[i] = level\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.scatter(range(len(level_arr)), level_arr, marker='.')\n",
    "plt.xlabel('Book Number')\n",
    "plt.ylabel('Mixture Level')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Step 7: Let's write out the actual text of the books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import format\n",
    "\n",
    "num_books = 10\n",
    "\n",
    "log_dist = np.empty(num_books)\n",
    "log_mixt = np.empty(num_books)\n",
    "log_tours = np.empty([num_books, 200])\n",
    "log_breakpoints = np.empty([num_books, 20])\n",
    "\n",
    "np.random.seed(30324)\n",
    "\n",
    "print(\"finished book \", end=\"\")\n",
    "for book_num in range(num_books):\n",
    "\n",
    "    mixture = int(level_arr[book_num])\n",
    "    version_name = f\"booknum{book_num}-mix{mixture}\"\n",
    "\n",
    "    seed = np.random.randint(1, high=1000)\n",
    "    tour, tracking_data = solver(dist_matrix, iters, temp, mixture, seed=seed)\n",
    "\n",
    "    breakpoints = get_break_points(tour)\n",
    "\n",
    "    log_dist[book_num] = tracking_data['dist_arr_a'][-1] + tracking_data['dist_arr_b'][-1]\n",
    "    log_mixt[book_num] = mixture\n",
    "    log_tours[book_num] = tour\n",
    "    log_breakpoints[book_num] = breakpoints\n",
    "\n",
    "    # Map poems and breaks to parts\n",
    "    part_1_items = []\n",
    "    part_2_items = []\n",
    "    for k, index in enumerate(tour):\n",
    "        if k < split_index:\n",
    "            if k in breakpoints:\n",
    "                part_1_items.append(\"<BREAK>\")\n",
    "            part_1_items.append(data_raw[index])\n",
    "        else:\n",
    "            if k in breakpoints:\n",
    "                part_2_items.append(\"<BREAK>\")\n",
    "            part_2_items.append(data_raw[index])\n",
    "    # Send to formatter script for rendering to PDF\n",
    "    format.render_version(\n",
    "        output_dir=\"output\",\n",
    "        output_name=version_name,\n",
    "        part_1_items=part_1_items,\n",
    "        part_2_items=part_2_items,\n",
    "        debug=False,\n",
    "    )\n",
    "    print(book_num, end=\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(log_tours)\n",
    "ax.set(xlabel = \"poem number\", ylabel=\"tour number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_index, row in enumerate(log_breakpoints):\n",
    "    x_values = row\n",
    "    y_values = [row_index] * len(row)\n",
    "\n",
    "    # Plot the points for the current row\n",
    "    plt.scatter(x_values, y_values, label=f'Row {row_index}', marker=\".\")\n",
    "\n",
    "plt.xlabel('Breakpoint in Book (poem number)')\n",
    "plt.ylabel('Book Number')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
